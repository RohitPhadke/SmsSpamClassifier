{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMS Spam Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WixBgYaNZNgh",
        "colab_type": "text"
      },
      "source": [
        "##**Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URzrVlRXX_s1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd # library for data analysis\n",
        "messages = pd.read_csv('/content/SMSSpamCollection', sep='\\t',\n",
        "                           names=[\"label\", \"message\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j-XdgoUZY2q",
        "colab_type": "text"
      },
      "source": [
        "##**Data cleaning and preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60VFL9taYQ0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re # Library for String searching and manipulation\n",
        "import nltk # Library for language processing\n",
        "nltk.download('stopwords') # Download the required package"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkS7KacsYdOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords # Library to remove stopwords\n",
        "from nltk.stem.porter import PorterStemmer # Library to implement stemming\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "for i in range(0, len(messages)):\n",
        "    review = re.sub('[^a-zA-Z]', ' ', messages['message'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxwUMQSEZi1_",
        "colab_type": "text"
      },
      "source": [
        "##**Creating the Bag of Words model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z2dNrU1Yf6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer #Library to convert a collection of text documents to a matrix of token counts\n",
        "cv = CountVectorizer(max_features=2500)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "\n",
        "y=pd.get_dummies(messages['label']) # Performing one-hot encoding onto to our target variables\n",
        "y=y.iloc[:,1].values # Remove 1 column from the generated dummy output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUfHIcHeZrnT",
        "colab_type": "text"
      },
      "source": [
        "##**Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVCA2Vf1YjXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split # Library to split dataset into train and test \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93gnuQoJZv4Z",
        "colab_type": "text"
      },
      "source": [
        "##**Training model using Naive bayes classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04HVNK7jYrwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB # Library to implement Naive Bayes classifier\n",
        "spam_detect_model = MultinomialNB().fit(X_train, y_train) # Training the model\n",
        "\n",
        "y_pred=spam_detect_model.predict(X_test) # Testing the model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ1aXRowZ5-X",
        "colab_type": "text"
      },
      "source": [
        "##**Create Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t-IOF2BYuje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix # Library to create a confusion matrix to evaluate the accuracy of the model\n",
        "conf_matrix = confusion_matrix(y_pred,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRFRaaN7Y78y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4bb06074-3b9e-403d-917d-d8e77b7b0370"
      },
      "source": [
        "conf_matrix"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[955,   7],\n",
              "       [ 11, 142]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7sHq1DPaDW7",
        "colab_type": "text"
      },
      "source": [
        "##**Checking the accuracy of our model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__y2BTVPY8pm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "72f4756b-4f9a-43f6-cfb7-a137d4cc458d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score # Library to get accuracy classification score\n",
        "accuracy = accuracy_score(y_pred,y_test)\n",
        "print(\"Accuracy is {:.2f}%\".format(accuracy*100))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 98.39%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}